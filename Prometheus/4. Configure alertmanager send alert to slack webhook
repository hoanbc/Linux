###Create slack channel and incomming webhook

###Config alertmanager
vim /etc/alertmanager/alertmanager.yml
global:
  resolve_timeout: 1m
  slack_api_url: 'https://hooks.slack.com/services/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'

route:
  receiver: 'slack_bot'
receivers:
- name: 'slack_bot'
  slack_configs:
  - channel: '#prometheus'
    send_resolved: true
    icon_url: https://avatars3.githubusercontent.com/u/3380462
    title: |-
     [{{ .Status | toUpper }}{{ if eq .Status "firing" }}:{{ .Alerts.Firing | len }}{{ end }}] {{ .CommonLabels.alertname }} for {{ .CommonLabels.job }}
     {{- if gt (len .CommonLabels) (len .GroupLabels) -}}
       {{" "}}(
       {{- with .CommonLabels.Remove .GroupLabels.Names }}
         {{- range $index, $label := .SortedPairs -}}
           {{ if $index }}, {{ end }}
           {{- $label.Name }}="{{ $label.Value -}}"
         {{- end }}
       {{- end -}}
       )
     {{- end }}
    text: >-
     {{ range .Alerts -}}
     *Alert:* {{ .Annotations.title }}{{ if .Labels.severity }} - `{{ .Labels.severity }}`{{ end }}

     *Description:* {{ .Annotations.description }}

     *Details:*
       {{ range .Labels.SortedPairs }} â€¢ *{{ .Name }}:* `{{ .Value }}`
       {{ end }}
     {{ end }}


###Config prometheus
vim /etc/prometheus/prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

alerting:
  alertmanagers:
  - scheme: https
    basic_auth:
      username: systemtest
      password: systemtest
    static_configs:
    - targets: ['prometheus.systemtest.xyz:9093']

rule_files:
  - "rules/basic.yml"

scrape_configs:
  - job_name: 'node_exporter'
    static_configs:
      - targets: ['192.168.1.151:9100']
        labels:
          hostname: 'srv-rhel1'
      - targets: ['192.168.1.152:9100']
        labels:
          hostname: 'srv-rhel2'

###Config prometheus alert rules
vim /etc/prometheus/rules/basic.yml
groups:
  - name: basic_check
    rules:
    - record: job:node_cpu_seconds:avg_idle
      expr: avg without(cpu)(rate(node_cpu_seconds_total{mode="idle"}[5m]))

    - alert: Node_Exporter_Down
      expr: up{job="node_exporter"} == 0
      for: 30s
      labels:
        severity: 'critical'
      annotations:
        summary: 'Host {{ $labels.hostname }} with IPR {{ $labels.instance }} down more than 5 second.'
